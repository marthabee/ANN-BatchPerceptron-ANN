{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khai báo thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lọc dữ liệu thành 2 loài"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_binary = data[data['Species'].isin(['Iris-setosa', 'Iris-versicolor'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chuẩn bị dữ liệu test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    # Map species to integers\n",
    "    data['Species'] = data['Species'].map({\n",
    "        'Iris-setosa': 0,\n",
    "        'Iris-versicolor': 1,\n",
    "    })\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = data.iloc[:, 1:-1].values\n",
    "    y = data['Species'].values\n",
    "    \n",
    "    # Split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AD Thuật toán Batch Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_perceptron(X, y, eta=0.1, epochs=100, tol=1e-5):\n",
    "    X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "    w = np.random.rand(X.shape[1])\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        predictions = np.dot(X, w)\n",
    "        errors = y - predictions\n",
    "        w += eta * np.dot(errors, X)\n",
    "        if np.all(np.abs(errors) < tol):\n",
    "            break\n",
    "    \n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    \n",
    "    return w, epoch + 1, execution_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "eta\t epochs\t num_epochs\t execution_time (s)\n",
      "0.01\t 100\t 100\t\t 0.003065\n",
      "0.01\t 500\t 500\t\t 0.007099\n",
      "0.01\t 1000\t 1000\t\t 0.016626\n",
      "0.05\t 100\t 100\t\t 0.001262\n",
      "0.05\t 500\t 500\t\t 0.010137\n",
      "0.05\t 1000\t 1000\t\t 0.022369\n",
      "0.1\t 100\t 100\t\t 0.002499\n",
      "0.1\t 500\t 500\t\t 0.006495\n",
      "0.1\t 1000\t 1000\t\t 0.021038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4428/36977729.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Species'] = data['Species'].map({\n",
      "/tmp/ipykernel_4428/4161769670.py:8: RuntimeWarning: invalid value encountered in add\n",
      "  w += eta * np.dot(errors, X)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data(data_binary)\n",
    "\n",
    "etas = [0.01, 0.05, 0.1]\n",
    "epoch_values = [100, 500, 1000]\n",
    "\n",
    "results = []\n",
    "\n",
    "for eta in etas:\n",
    "    for epochs_val in epoch_values:\n",
    "        w, num_epochs, exec_time = batch_perceptron(X_train, y_train, eta=eta, epochs=epochs_val)\n",
    "        results.append({\n",
    "            'eta': eta,\n",
    "            'epochs': epochs_val,\n",
    "            'num_epochs': num_epochs,\n",
    "            'execution_time': exec_time\n",
    "        })\n",
    "\n",
    "\n",
    "print(\"Results:\")\n",
    "print(\"eta\\t epochs\\t num_epochs\\t execution_time (s)\")\n",
    "for result in results:\n",
    "    print(f\"{result['eta']}\\t {result['epochs']}\\t {result['num_epochs']}\\t\\t {result['execution_time']:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
